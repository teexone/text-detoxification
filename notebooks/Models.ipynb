{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us train sequence-to-sequence models to perform a task of translation of toxic sentences to non-toxic versions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Models\n",
    "\n",
    "I decided to use the same model architecture as mentioned in [1] - T5. But instead, I trained it on the parallel corpus, ParaMNT instead of the original corpora, Jigsaw. The reason for this is to experiment with the setting of the model and parallel dataset, instead of using unsupervised approach as in the paper."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before anything, we firstly need to derive metrics for the task. I will be using metrics provided by [1] using their source code and toxicity classfier provided by them. The metrics are as follows:\n",
    "\n",
    "1. Toxicity: Toxicity score of the generated sentence and a difference between the toxicity score of the generated sentence and the original non-toxic sentence.\n",
    "2. Fluency: Fluency score of the generated sentence and a difference between the fluency score of the generated sentence and the original non-toxic sentence.\n",
    "3. Meaning Preservation: BLEU score between the generated sentence and the original non-toxic sentence.\n",
    "4. Semantic Similarity: Semantic similarity score between the generated sentence and the original non-toxic sentence."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Firstly, let us try to train sequence-to-sequence T5 model to perform the task of translation of toxic sentences to non-toxic versions. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from transformers import (\n",
    "    T5ForConditionalGeneration, \n",
    "    T5Tokenizer, \n",
    "    DataCollatorForSeq2Seq, \n",
    "    Seq2SeqTrainer, \n",
    "    Seq2SeqTrainingArguments\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_FOLDER = os.path.join(os.getcwd(), '..', 'data')\n",
    "DATASET_FILE = os.path.join(DATA_FOLDER, 'raw', 'filtered.tsv')\n",
    "MODEL_FOLDER = os.path.join(os.getcwd(), '..', 'models')\n",
    "MODEL_PREFIX = os.path.join(MODEL_FOLDER, 'tokenizer')\n",
    "VOCAB_SIZE = 10000 # spiece"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using the default legacy behaviour of the <class 'transformers.models.t5.tokenization_t5.T5Tokenizer'>. This is expected, and simply means that the `legacy` (previous) behavior will be used so nothing changes for you. If you want to use the new behaviour, set `legacy=False`. This should only be set if you understand what it means, and thouroughly read the reason why this was added as explained in https://github.com/huggingface/transformers/pull/24565\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "model: T5ForConditionalGeneration = T5ForConditionalGeneration.from_pretrained('t5-small')\n",
    "tokenizer: T5Tokenizer = T5Tokenizer.from_pretrained('t5-small')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd_data = pd.read_csv(os.path.join(DATA_FOLDER, 'raw', 'filtered.tsv'), sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare data for training\n",
    "source = pd_data['translation'].tolist()\n",
    "target = pd_data['reference'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "torch.manual_seed(705)\n",
    "np.random.seed(705)\n",
    "\n",
    "source_val_train, source_test, target_val_train, target_test = train_test_split(source, target, test_size=0.2)\n",
    "source_train, source_val, target_train, target_val = train_test_split(source_val_train, target_val_train, test_size=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training\n",
    "\n",
    "The model will train on sequence-to-sequence task with a helo "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import DataCollatorForSeq2Seq\n",
    "\n",
    "def tokenize_function(examples):\n",
    "    \"\"\"\n",
    "    Tokenize the examples\n",
    "    \n",
    "    :param examples: the examples to tokenize\n",
    "    \n",
    "    :return: the tokenized examples\n",
    "    \"\"\"\n",
    "    inputs = tokenizer.batch_encode_plus(\n",
    "        examples['translation'], \n",
    "        padding='max_length',\n",
    "        max_length=512,\n",
    "        add_special_tokens=True,\n",
    "        truncation=True,\n",
    "    )\n",
    "    \n",
    "    labels = tokenizer.batch_encode_plus(\n",
    "        examples['reference'], \n",
    "        padding='max_length',\n",
    "        max_length=512,\n",
    "        add_special_tokens=True,\n",
    "        truncation=True,\n",
    "    ).input_ids\n",
    "    \n",
    "    labels_with_ignore_index = []\n",
    "    for labels_example in labels:\n",
    "        # Replace 0 with -100 (T5 default ignore index)\n",
    "        labels_example = [label if label != 0 else -100 for label in labels_example]\n",
    "        labels_with_ignore_index.append(labels_example)\n",
    "    \n",
    "    inputs['labels'] = labels_with_ignore_index\n",
    "    \n",
    "    return inputs\n",
    "\n",
    "data_collator = DataCollatorForSeq2Seq(tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "59f6ff1f509d4a1aa8448d739e5ffe33",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=6):   0%|          | 0/369776 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/lib/python3.11/site-packages/datasets/table.py:1395: FutureWarning: promote has been superseded by mode='default'.\n",
      "  block_group = [InMemoryTable(cls._concat_blocks(list(block_group), axis=axis))]\n",
      "/root/miniconda3/lib/python3.11/site-packages/datasets/table.py:1421: FutureWarning: promote has been superseded by mode='default'.\n",
      "  table = cls._concat_blocks(blocks, axis=0)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "438e2b21935b4fadaffe5cee9a6fa157",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=6):   0%|          | 0/92445 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/lib/python3.11/site-packages/datasets/table.py:1395: FutureWarning: promote has been superseded by mode='default'.\n",
      "  block_group = [InMemoryTable(cls._concat_blocks(list(block_group), axis=axis))]\n",
      "/root/miniconda3/lib/python3.11/site-packages/datasets/table.py:1421: FutureWarning: promote has been superseded by mode='default'.\n",
      "  table = cls._concat_blocks(blocks, axis=0)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f2ed5468b5ba42d8a793f72692653906",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=6):   0%|          | 0/115556 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/lib/python3.11/site-packages/datasets/table.py:1395: FutureWarning: promote has been superseded by mode='default'.\n",
      "  block_group = [InMemoryTable(cls._concat_blocks(list(block_group), axis=axis))]\n",
      "/root/miniconda3/lib/python3.11/site-packages/datasets/table.py:1421: FutureWarning: promote has been superseded by mode='default'.\n",
      "  table = cls._concat_blocks(blocks, axis=0)\n"
     ]
    }
   ],
   "source": [
    "# Tokenize data\n",
    "from datasets import Dataset\n",
    "\n",
    "train_dataset = Dataset.from_dict({'translation': source_train, 'reference': target_train})\n",
    "val_dataset = Dataset.from_dict({'translation': source_val, 'reference': target_val})\n",
    "test_dataset = Dataset.from_dict({'translation': source_test, 'reference': target_test})\n",
    "\n",
    "train_dataset = train_dataset.map(tokenize_function, batched=True, batch_size=512, num_proc=6)\n",
    "val_dataset = val_dataset.map(tokenize_function, batched=True, batch_size=512, num_proc=6)\n",
    "test_dataset = test_dataset.map(tokenize_function, batched=True, batch_size=512, num_proc=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train model\n",
    "\n",
    "from transformers import Seq2SeqTrainer, Seq2SeqTrainingArguments\n",
    "\n",
    "batch_size = 35\n",
    "num_epochs = 1\n",
    "learning_rate = 5e-5\n",
    "warmup_steps = 500\n",
    "weight_decay = 0.01\n",
    "\n",
    "\n",
    "training_args = Seq2SeqTrainingArguments(\n",
    "    output_dir=MODEL_FOLDER,\n",
    "    per_device_train_batch_size=batch_size,\n",
    "    per_device_eval_batch_size=batch_size,\n",
    "    predict_with_generate=True,\n",
    "    do_train=True,\n",
    "    do_eval=True,\n",
    "    logging_steps=1000,\n",
    "    save_steps=1000,\n",
    "    eval_steps=1000,\n",
    "    overwrite_output_dir=True,\n",
    "    warmup_steps=warmup_steps,\n",
    "    learning_rate=learning_rate,\n",
    "    weight_decay=weight_decay,\n",
    "    num_train_epochs=num_epochs,\n",
    "    report_to=\"none\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Seq2SeqTrainer(\n",
    "    model=model,\n",
    "    tokenizer=tokenizer,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=val_dataset,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1300' max='1300' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1300/1300 02:51, Epoch 100/100]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>3.225400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>2.943300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>2.584600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>2.233100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>1.882700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>1.567800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>700</td>\n",
       "      <td>1.332400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>1.135300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>900</td>\n",
       "      <td>0.999800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.896500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1100</td>\n",
       "      <td>0.813800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1200</td>\n",
       "      <td>0.771800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1300</td>\n",
       "      <td>0.757300</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=1300, training_loss=1.6264456763634314, metrics={'train_runtime': 171.6048, 'train_samples_per_second': 58.273, 'train_steps_per_second': 7.576, 'total_flos': 1353418014720000.0, 'train_loss': 1.6264456763634314, 'epoch': 100.0})"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(\"I know you hate me, but I don't make a cow out of myself, and I don't lecture you.\",\n",
       " \"I know you hate me. But this isn't me being some overbearing bitch.\")"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_sample = train_dataset[4]\n",
    "train_sample['translation'], train_sample['reference']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"<pad> I know you hate me, but I don't give you a lame.</s>\""
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test model\n",
    "\n",
    "input_ids = train_sample['input_ids']\n",
    "attention_mask = train_sample['attention_mask']\n",
    "\n",
    "outputs = model.generate(\n",
    "    input_ids=torch.tensor(input_ids).unsqueeze(0).to('cuda'),\n",
    "    attention_mask=torch.tensor(attention_mask).unsqueeze(0).to('cuda'),\n",
    "    max_length=512,\n",
    "    num_beams=5,\n",
    "    early_stopping=True\n",
    ")\n",
    "\n",
    "tokenizer.decode(outputs[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "end_trainer = Seq2SeqTrainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=val_dataset,\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=data_collator,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='10566' max='10566' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [10566/10566 1:25:29, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>2.536200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>2.336400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>2.268400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4000</td>\n",
       "      <td>2.249800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5000</td>\n",
       "      <td>2.223500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6000</td>\n",
       "      <td>2.210500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7000</td>\n",
       "      <td>2.208100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8000</td>\n",
       "      <td>2.199600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9000</td>\n",
       "      <td>2.195400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10000</td>\n",
       "      <td>2.191600</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=10566, training_loss=2.2582586816646555, metrics={'train_runtime': 5129.9381, 'train_samples_per_second': 72.082, 'train_steps_per_second': 2.06, 'total_flos': 5.004614998111027e+16, 'train_loss': 2.2582586816646555, 'epoch': 1.0})"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "end_trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "DETOK_MODEL_FOLDER = os.path.join(MODEL_FOLDER, 't5-detox')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "# Save model\n",
    "\n",
    "model.save_pretrained(DETOK_MODEL_FOLDER)\n",
    "tokenizer.save_pretrained(DETOK_MODEL_FOLDER)\n",
    "\n",
    "# Load model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "loaded = T5ForConditionalGeneration.from_pretrained(DETOK_MODEL_FOLDER)\n",
    "loaded_tokenizer = T5Tokenizer.from_pretrained(DETOK_MODEL_FOLDER)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test loaded model on whole test dataset\n",
    "# Generate predictions for each of reference sentences\n",
    "# and save them to two text files\n",
    "\n",
    "# One contain predictions, other contain references\n",
    "# each line in both files correspond to one sentence\n",
    "\n",
    "def generate_translation(batch):\n",
    "    input_ids = torch.tensor(batch['input_ids']).to('cuda')\n",
    "    attention_mask = torch.tensor(batch['attention_mask']).to('cuda')\n",
    "    \n",
    "    outputs = loaded.generate(\n",
    "        input_ids=input_ids,\n",
    "        attention_mask=attention_mask,\n",
    "        max_length=512,\n",
    "        num_beams=5,\n",
    "        early_stopping=True\n",
    "    )\n",
    "    \n",
    "    return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "115556\n"
     ]
    }
   ],
   "source": [
    "print(len(target_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7222cded9b464592b34c5659bbd60dc0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1024 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['translation', 'reference', 'input_ids', 'attention_mask', 'labels'],\n",
       "    num_rows: 1024\n",
       "})"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Iterate over test dataset and generate predictions\n",
    "# for each of reference sentences\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "loaded.to('cuda')\n",
    "\n",
    "predictions = []\n",
    "references = []\n",
    "\n",
    "def gen(batch):\n",
    "    outputs = generate_translation(batch)\n",
    "    \n",
    "    predictions.extend([loaded_tokenizer.decode(ids) for ids in outputs])\n",
    "    references.extend(batch['translation'])\n",
    "    \n",
    "test_dataset.select(range(1024)).map(gen, batched=True, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('Calling her ridiculously naive would be a compliment.',\n",
       " 'To call it ridiculously naive would have been a compliment.',\n",
       " 'calling her ridiculously naive would be a compliment.')"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_sample = test_dataset[4]\n",
    "\n",
    "_g = loaded.to('cuda').generate(\n",
    "    input_ids=torch.tensor(test_sample['input_ids']).unsqueeze(0).to('cuda'),\n",
    "    max_length=512,\n",
    "    num_beams=5,\n",
    "    early_stopping=True\n",
    ")\n",
    "\n",
    "loaded_tokenizer.decode(_g[0], skip_special_tokens=True), test_sample['reference'], test_sample['translation']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(DATA_FOLDER, 'interim', 'references.txt'), 'w+') as f:\n",
    "    f.write('\\n'.join(references))\n",
    "    \n",
    "with open(os.path.join(DATA_FOLDER, 'interim', 'predictions.txt'), 'w+') as f:\n",
    "    f.write('\\n'.join(predictions))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
